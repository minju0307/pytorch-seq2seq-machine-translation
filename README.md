# NLP_code_assignment1

ìƒì„± ì¼ì‹œ: 2022ë…„ 10ì›” 11ì¼ ì˜¤ì „ 10:41
ì§„í–‰: ì§„í–‰
íƒœê·¸: class

## 3 - Neural Machine Translation by Jointly Learning to Align and Translate

### Introduction

### `previous model`

- decoderì—ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë“  time-stepë§ˆë‹¤ ë‹¤ìŒì„ linear layer ğ‘“ ì— inputìœ¼ë¡œ ë„£ìŒ
    - encoder context vector ğ‘§
    - embedded input word ğ‘‘(ğ‘¦ğ‘¡)
    - decoder hidden state ğ‘ ğ‘¡
- ì´ëŸ¬í•œ ë°©ì‹ì€ encoder ë¬¸ì¥ì˜ ì •ë³´ì˜ ì†ì‹¤ì„ ìµœì†Œí•œìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, ë””ì½”ë”ì—ì„œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë§¤ time-stepë§ˆë‹¤ ì¸ì½”ë”ì˜ ì „ì²´ ë¬¸ì¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ë˜‘ê°™ì´ ê³„ì† ë³¸ë‹¤ëŠ” ë¬¸ì œì ì´ ìˆìŒ

### `Attention`

- attentionì„ í†µí•´ì„œ encoderì˜ source sentence ì¤‘ decoderì˜ ì´ë²ˆ time-stepì—ì„œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°ì— ê°€ì¥ ê´€ë ¨ì´ í° ë‹¨ì–´ì— ì£¼ëª©í•˜ê²Œ í•˜ëŠ” íš¨ê³¼ë¥¼ ì¤„ ìˆ˜ ìˆìŒ
- source sentenceì˜ ê¸¸ì´ë§Œí¼ì˜ í¬ê¸°ì¸ attention vector ğ‘ ë¥¼ ê³„ì‚°í•  ê²ƒ
- attention vectorëŠ” ê° ìš”ì†Œê°€ 0ì—ì„œ 1ì‚¬ì´ì´ê³ , í•©ì€ 1ì¸ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆìŒ
- ì´í›„ source sentenceì˜ hidden statesì™€ ê°€ì¤‘í•© í•˜ëŠ” ê³¼ì •ì„ í†µí•´ì„œ weighted source vector ğ‘¤ì„ ê³„ì‚°í•¨

---

### Encoder

### `bidirectional RNN`

- a single layer GRU ë¡œ êµ¬í˜„í•˜ê³ 
- ë˜í•œ bidirectional RNN ì„ í™œìš©í•˜ì—¬ ì´ì „ ë‹¨ì–´ì˜ ë¬¸ë§¥ ë¿ ì•„ë‹ˆë¼ ë‹¤ìŒ ë‹¨ì–´ì˜ ë¬¸ë§¥ë„ ë°˜ì˜í•˜ê³ ì í•¨
    - two RNNs in each layer
    - A forward RNN: ë¬¸ì¥ì˜ ì™¼ìª½ë¶€í„° ì˜¤ë¥¸ìª½ê¹Œì§€ë¥¼ ì§€ë‚˜ë©° embedding
    - A backward RNN: ë¬¸ì¥ì˜ ì˜¤ë¥¸ìª½ë¶€í„° ì™¼ìª½ê¹Œì§€ë¥¼ ì§€ë‚˜ë©° embedding

![Untitled](assets/Untitled.png)

- ìˆ˜ì‹ ì˜ë¯¸: time step t ì—ì„œì˜ ê° ë°©í–¥ encoder hidden states â„â†’ğ‘¡ ëŠ”
    - inputìœ¼ë¡œ ë‹¤ìŒì˜ 2ê°€ì§€ë¥¼ ë°›ê³ 
        - embedded word ğ‘’(ğ‘¥â†’ğ‘¡),
        - ì´ì „ time step t-1ì—ì„œì˜ encoder hidden states â„â†’ğ‘¡âˆ’1
    - ì´ë¥¼ bidirectional RNN (GRUëŠ” í•„ìš”í•œ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê¸° ìœ„í•´ ë°œì „ëœ RNNì˜ í•œ ì¢…ë¥˜) ë¥¼ ê±°ì³ì„œ ì‚°ì¶œë¨
- bidirectional RNNì„ ê±°ì¹˜ê²Œ ë˜ë©´ 2ê°œì˜ context vectorë¥¼ ì–»ê²Œ ë¨
    - forward RNN ë°©í–¥ì—ì„œ ë¬¸ì¥ì˜ ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ ë³¸ ì´í›„ ì‚°ì¶œë˜ëŠ” context vector ğ‘§â†’=â„â†’ğ‘‡
    - backward RNN ë°©í–¥ì—ì„œ ë¬¸ì¥ì˜ ì²« ë‹¨ì–´ë¥¼ ë³¸ ì´í›„ ì‚°ì¶œë˜ëŠ”context vector ğ‘§â†=â„â†ğ‘‡

### `RNN returns`

- outputs
    - size: **[src len, batch size, hid dim * num directions]**
    - 3ë²ˆì§¸ ì°¨ì›ì€ forwardì™€ backwardì˜ hidden statesê°€ concatenated ë˜ì–´ì„œ í•¨ê»˜ ë‚˜íƒ€ë‚˜ê²Œ ë¨.
        - ì˜ˆ) â„1=[â„â†’1;â„â†ğ‘‡], â„2=[â„â†’2;â„â†ğ‘‡âˆ’1]
    - encoder hidden statesë¼ê³  í•˜ë©´ forward and backward concatenated ëœ ëª¨ë“  ê²ƒì„ ì˜ë¯¸í•˜ë©° ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•¨
        - ğ»={â„1,â„2,...,â„ğ‘‡}
    - ì˜ˆë¥¼ ë“¤ì–´ src len=4, batch size=1, hid dim=4ë¼ê³  í•  ë•Œì˜ outputs (ì½”ë“œì— ë‚˜ì™€ìˆëŠ” ë°”ì™€ ê°™ì´ last layerë§Œ ì‚°ì¶œëœë‹¤ê³  í–ˆì„ ë•Œ)
    
    ```python
    [[[â„â†’1;â„â†ğ‘‡]],
     [[â„â†’2;â„â†ğ‘‡âˆ’1]],
     [[â„â†’3;â„â†ğ‘‡âˆ’2]],
     [[â„â†’4;â„â†ğ‘‡âˆ’3]]]
    
    #T=4
    #3ë²ˆì§¸ ì°¨ì›ì˜ ì›ì†Œì˜ ê°œìˆ˜ëŠ” 8 (4*2)
    ```
    
- hidden
    - size: **[n layers*num directions, batch size, hid dim]**
    - **[-2, :, :]** ëŠ” forward RNNì˜ ìµœì¢… hidden state (ë§¨ ì˜¤ë¥¸ìª½ ë‹¨ì–´ê¹Œì§€ ë‹¤ ë³¸ í›„)
    - **[-1, :, :]**ëŠ” backward RNNì˜ ìµœì¢… hidden state (ë§¨ ì™¼ìª½ ë‹¨ì–´ê¹Œì§€ ë‹¤ ë³¸ í›„)
    - ì˜ˆë¥¼ ë“¤ì–´ n layers=4, batch size=1, hid dim=4ì¼ ë•Œì˜ hidden
    
    ```python
    [[[â„â†’1]],
     [[â„â†ğ‘‡]],
     [[â„â†’2]],
     [[â„â†ğ‘‡âˆ’1]],
     [[â„â†’3]],
     [[â„â†ğ‘‡âˆ’2]],
     [[â„â†’4]],
     [[â„â†ğ‘‡âˆ’3]]]
    
    #T=4
    #3ë²ˆì§¸ ì°¨ì›ì˜ ì›ì†Œì˜ ê°œìˆ˜ëŠ” 4 (=hid dim)
    ```
    

### `context vector`

- decoderëŠ” bidirectionì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— initial hidden state ğ‘ 0 ì—ëŠ” single context vector ğ‘§ë¥¼ ì‚¬ìš©í•  ìˆ˜ ë°–ì— ì—†ìŒ
- í˜„ì¬ encoderì—ì„œëŠ” forward ì™€ backward 2ê°œì˜ hidden stateê°€ ìˆê¸° ë•Œë¬¸ì— ì´ ë‘˜ì„ concatenatingí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë¥¼ í•´ê²°í•¨

![Untitled](assets/Untitled%201.png)

- ìˆ˜ì‹ì˜ ì˜ë¯¸
    - 1) forwardì™€ backwardì˜ final time-stamp hidden state (â„â†’ğ‘‡,â„â†ğ‘‡) ë¥¼ concatenateí•¨
    - 2) ì´ë¥¼ linear layer ğ‘”ë¥¼ ê±°ì¹˜ê²Œ í•˜ê³ 
    - 3) ì´ ê²°ê³¼ë¬¼ì— tanh activation function ì„ ê±°ì¹˜ê²Œ í•¨
    
    â†’ ì´ë¥¼ í†µí•´ ìµœì¢… encoderì˜ single context vectorì´ì decoderì˜ initial hidden stateë¥¼ ì‚¬ìš©í•¨ 
    
- ì´ ìˆ˜ì‹ì˜ ê²½ìš° paperì™€ ë‹¤ë¥´ê²Œ ì¡°ê¸ˆ ìˆ˜ì •ë˜ì—ˆëŠ”ë°,
    - paperì—ì„œëŠ” ì˜¤ì§ backward RNN hidden stateë§Œì„ ì‚¬ìš©í•˜ì§€ë§Œ
    - ì´ ìˆ˜ì‹ì—ì„œëŠ” bidirection ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ë„ë¡ ìˆ˜ì •ë˜ì—ˆìŒ

### `code ì„¤ëª…`

- `embedded = self.dropout(self.embedding(src))`
    - src=[src len, batch size]ë¡œ, ì˜ˆë¥¼ ë“¤ì–´ batch.srcì˜ ê²°ê³¼ë¥¼ ì‚´í´ë³¼ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì´ë£¨ì–´ì ¸ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
    
    ```python
    tensor([[  2,   2,   2,  ...,   2,   2,   2],
            [ 18,   8,  17,  ...,   8,  18,  18],
            [103,  16, 523,  ...,  36, 103, 168],
            ...,
            [  1,   1,   1,  ...,   1,   1,   1],
            [  1,   1,   1,  ...,   1,   1,   1],
            [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')
    ```
    
    - srcëŠ” ê° í† í°ë³„ í† í°ì˜ idë¡œ ë³€í™˜ëœ í›„, batchë¡œ ë¬¶ì–´ì„œ ì €ì¥ë˜ì–´ ìˆëŠ” inputì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
    - embedding layerëŠ” dictionary sizeë§Œí¼ì˜ embedding lookup tableì´ ì¡´ì¬í•˜ê³ , ì´ lookup tableì—ì„œ í† í°ì˜ id, ì¦‰ indexì˜ í–‰ì„ ê°€ì ¸ì™€ embeddingì„ ë¶™ì´ê²Œ ëœë‹¤.
    - self.embeddingì€ ì´ë¥¼ ì„ë² ë”©í•˜ëŠ” ì—­í• ì„ í•˜ëŠ”ë°, nn.Embeddingì€ inputì— embedding_dimì´ ì¶”ê°€ë˜ëŠ” í˜•íƒœì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
    
    ```python
    #src = [src len, batch size]
            
    embedded = self.dropout(self.embedding(src))
            
    #embedded = [src len, batch size, emb dim]
    ```
    
- `outputs, hidden = self.rnn(embedded)`
    - rnnì˜ inputì€ embededë¡œ sizeëŠ” [src len, batch size, emb dim]ì´ë‹¤.
    - rnn ì…€ì˜ ì—°ì‚°ì€ `self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)` ì—ì„œ bidirectionalë¡œ ì´ë£¨ì–´ì§„ë‹¤.
    - ê°ê° forwardì™€ bacwardì˜ ì—°ì‚°ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë©°, ê°ê°ì˜ ì—°ì‚°ì€ ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë˜ ìˆ˜ì‹ì— ë§¤ì¹­ëœë‹¤.
      
        ![Untitled](assets/Untitled%202.png)
        
        - ğ‘’(ğ‘¥â†’ğ‘¡) ì€ ê° time-step ë³„ embededëœ í† í°ì„ ì˜ë¯¸í•˜ê³ , ì´ì „ time-stepì—ì„œì˜ hidden stateëŠ” ë‹¤ìŒ time-stepì—ì„œì˜ hidden stateë¥¼ êµ¬í•˜ëŠ” ë°ì— inputìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.
    - outputsëŠ” **[src len, batch size, hid dim * num directions]** ì˜ sizeë¡œ ì´ë£¨ì–´ì ¸ ìˆê³ , last layerì—ì„œì˜ outputì„ ì˜ë¯¸í•œë‹¤. ê° time-step ë³„ forwardì™€ backwardì˜ hidden stateê°€ í•¨ê»˜ ë‚˜íƒ€ë‚œë‹¤.  ì•„ë˜ëŠ” ê·¸ ì˜ˆì‹œì´ë‹¤. (batch sizeê°€ 1ì´ë¼ê³  ê°€ì •)
      
        ```python
        [[[â„â†’1;â„â†ğ‘‡]],
         [[â„â†’2;â„â†ğ‘‡âˆ’1]],
         [[â„â†’3;â„â†ğ‘‡âˆ’2]],
         [[â„â†’4;â„â†ğ‘‡âˆ’3]]]
        ```
        
    - hiddenì€ ëª¨ë“  layerì—ì„œì˜ hidden stateê°€ stackë˜ì–´ ë‚˜íƒ€ë‚˜ì§€ë§Œ, ë³¸ ì½”ë“œì—ì„œëŠ” layerê°€ í•œê°œ ì´ë¯€ë¡œ í•˜ë‚˜ì˜ layerì— ëŒ€í•œ forward, backward hidden stateê°€ ì°¨ë¡€ë¡œ ìŒ“ì—¬ìˆë‹¤.  ì•„ë˜ëŠ” ê·¸ ì˜ˆì‹œì´ë‹¤. (batch sizeê°€ 1ì´ë¼ê³  ê°€ì •)
      
        ```python
        [[[â„â†’1]],
         [[â„â†ğ‘‡]]]
        ```
        
    - `hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))`
        - encoderì˜ single context vectorì´ì decoderì˜ initial hidden stateë¥¼ ì‚°ì¶œí•˜ëŠ” ì½”ë“œì´ë‹¤.
        - ë”°ë¼ì„œ ì•„ë˜ì˜ ìˆ˜ì‹ì— ëŒ€ì‘ëœë‹¤.
        
        ![Untitled](assets/Untitled%203.png)
        
        - forwardì™€ backwardì˜ context vectorë¥¼ concatí•œ í›„ì— linear layerë¥¼ ê±°ì¹˜ê³ , tanh activation functionì„ ê±°ì¹œë‹¤.
        - ì´ë¡œì¨ hiddenì€ [batch size, decoder hid dim]ì˜ sizeë¥¼ ê°€ì§€ê²Œ ëœë‹¤.

---

### Attention

### `attention layer`

- input
    - decoderì˜ ì´ì „ hidden state ğ‘ ğ‘¡âˆ’1
    - encoderì˜ ëª¨ë“  forwardì™€ backward hidden stateê°€ stackëœ ğ»
      
        (ìœ„ì—ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´ â„1=[â„â†’1;â„â†ğ‘‡], â„2=[â„â†’2;â„â†ğ‘‡âˆ’1] ì¼ ë•Œ ğ»={â„1,â„2,...,â„ğ‘‡} )
    
- output
    - attention vector ğ‘ğ‘¡
        - length = source sentence
        - ğ‘ğ‘¡ ë²¡í„°ì˜ ê° ìš”ì†ŒëŠ” 0ê³¼ 1ì‚¬ì´ì˜ ê°’ì„ ê°–ê³ , ëª¨ë“  ìš”ì†Œë“¤ì˜ í•©ì€ 1ì´ë‹¤.

â†’ ğ‘ğ‘¡ ëŠ” ë‹¤ìŒ ë‹¨ì–´ë¥¼ decoderì—ì„œ ì˜ˆì¸¡í•  ë•Œ source sentenceì˜ ì–´ë–¤ ë‹¨ì–´ë° ë” ë§ì´ ì£¼ëª©í•´ì•¼ í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ë‹¤. 

### `Energy`

- ì²« ë²ˆì§¸ë¡œ ê³„ì‚°í•  ê²ƒì€ previous decoder hidden stateì™€ encoder hidden state ì‚¬ì´ì˜ energyë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤.
- encoder hidden state ğ»={â„1,â„2,...,â„ğ‘‡} ëŠ” Tê°œì˜ tensorì´ê³ , decoder hidden state ğ‘ ğ‘¡âˆ’1ëŠ” í•˜ë‚˜ì˜ tensorì´ë¯€ë¡œ, ğ‘ ğ‘¡âˆ’1ë¥¼ T íƒ€ì„ `repeat` í•˜ì—¬ ê³„ì‚°í•œë‹¤.

![Untitled](assets/Untitled%204.png)

- ìˆ˜ì‹ì˜ ì˜ë¯¸
    - 1) ğ‘ ğ‘¡âˆ’1ì™€ ğ»ë¥¼ ê°ê° concatí•œë‹¤.
        - ì˜ˆì‹œ: [ğ‘ ğ‘¡âˆ’1;â„1], â€¦ , [ğ‘ ğ‘¡âˆ’1;â„T]
    - 2) linear layer `attn` ì„ ì§€ë‚œë‹¤.
    - 3) tanh activation functionì„ ì§€ë‚œë‹¤.

â†’ ì´ë¥¼ í†µí•´ì„œ encoderì˜ hidden stateê°€ decoder hidden stateì™€ ì–¼ë§ˆë‚˜ ì˜ â€œmatchâ€ ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 

### `attention vector`

- í•˜ë‚˜ì˜ exampleì— ëŒ€í•´ì„œ ğ¸ğ‘¡ ëŠ” **[dec hid dim, src len]**ì˜ sizeë¥¼ ê°–ëŠ”ë‹¤.
- ì´ê²ƒì˜ sizeë¥¼ **[src len]** ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•œë‹¤.
  
    ![Untitled](assets/Untitled%205.png)
    
- ìˆ˜ì‹ì˜ ì˜ë¯¸: ğ¸ğ‘¡ì˜ sizeë¥¼ **[dec hid dim, src len]** â†’ **[src len]** ìœ¼ë¡œ ë³€í™˜ì‹œí‚¤ê¸° ìœ„í•´ [1, dec hid dim]ì„ ê°€ì§€ëŠ” tensor ğ‘£ë¥¼ ê³±í•´ì¤€ë‹¤.
- ğ‘£ ëŠ” energyì˜ ê°€ì¤‘í•©ì—ì„œ ê°€ì¤‘ì¹˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ì²˜ìŒì—ëŠ” randomí•˜ê²Œ ì´ˆê¸°í™”ë˜ì§€ë§Œ backpropagationì„ í†µí•´ì„œ í•™ìŠµëœë‹¤.
- ğ‘£ ëŠ” biasê°€ ì—†ëŠ” linear layerë¡œ êµ¬í˜„ëœë‹¤.

- softmax í•¨ìˆ˜ë¥¼ ê±°ì³ ìµœì¢… ë²¡í„° ì‚°ì¶œí•˜ê¸°
  
    ![Untitled](assets/Untitled%206.png)
    
- attention vectorì˜ ëª¨ë“  ìš”ì†Œê°€ 0ê³¼ 1ì‚¬ì´ì˜ ê°’ì„ ê°–ê²Œ ë˜ê³ , ê·¸ ì•ì´ 1ì´ ëœë‹¤.

### `code ì„¤ëª…`

- `self**.**attn **=** nn**.**Linear((enc_hid_dim ***** 2) **+** dec_hid_dim, dec_hid_dim)`
  
    ![Untitled](assets/Untitled%207.png)
    
    - ì´ ìˆ˜ì‹ì—ì„œ atten layerë¥¼ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.
    - inputìœ¼ë¡œ  [ğ‘ ğ‘¡âˆ’1;â„1], â€¦ , [ğ‘ ğ‘¡âˆ’1;â„T] ê°€ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— inputì˜ ì°¨ì›ì€ `(enc_hid_dim ***** 2) **+** dec_hid_dim` ê°€ ë˜ê³ 
    - outputìœ¼ë¡œëŠ” `dec_hid_dim` ì„ ë°˜í™˜í•˜ê²Œ ëœë‹¤.

- `self**.**v **=** nn**.**Linear(dec_hid_dim, 1, bias **=** **False**)`
  
    ![Untitled](assets/Untitled%208.png)
    
    - ì´ ìˆ˜ì‹ì—ì„œ ğ‘£ë¥¼ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì´ë‹¤.
    - ğ‘£ ëŠ” ğ¸ğ‘¡ì™€ ê³±í•´ì ¸ ì°¨ì›ì„  **[dec hid dim, src len]** â†’ **[src len]**  ë¡œ ë³€í™”ì‹œí‚¤ì´ê¸°ì— (`dec_hid_dim, 1`) ì°¨ì›ìœ¼ë¡œ êµ¬í˜„ëœë‹¤.
    
- `hidden **=** hidden**.**unsqueeze(1)**.**repeat(1, src_len, 1)`
    - ì²« ë²ˆì§¸ hidden (s0) ì€ encoderì˜ ìµœì¢… context vectorë¡œì¨, **[batch size, decoder hid dim]** ì˜ sizeë¥¼ ê°€ì§€ê³  ìˆë‹¤.
    - ì´ë¥¼ `unsqueeze(1)`ì„ í•˜ê²Œ ë˜ë©´ ì´ sizeëŠ” **[batch size, 1, decoder hid dim]** ë¡œ ë³€í™˜ëœë‹¤. (unsqueeze(1)ëŠ” dim 1ì— 1ì°¨ì›ì„ ì¶”ê°€)
    - ì´ë¥¼ `repeat(1, src_len, 1)` í•˜ê²Œë˜ë©´, **[batch size, src_len, decoder hid dim]** ë¡œ ì°¨ì›ì´ ë³€í™˜ëœë‹¤.
    
- `energy **=** torch**.**tanh(self**.**attn(torch**.**cat((hidden, encoder_outputs), dim **=** 2)))`
  
    ![Untitled](assets/Untitled%209.png)
    
    - ìˆ˜ì‹ì— ëŒ€ì‘ë˜ëŠ” ë¶€ë¶„ì´ë‹¤.
    - `torch**.**cat((hidden, encoder_outputs), dim **=** 2)`ì„ í†µí•´ì„œ
    
    ```
    #hidden = [batch size, src len, dec hid dim]
    #encoder_outputs = [batch size, src len, enc hid dim * 2]
    ```
    
    - ì˜€ë˜ ì°¨ì›ì´ **[batch size, src len, enc hid dim * 2 + dec hid dim ]** ìœ¼ë¡œ ë³€í™”í•˜ê²Œ ë˜ê³  3ë²ˆì¬ ì°¨ì›ì´ attn layerì˜ input ì°¨ì›ê³¼ ë™ì¼í•´ì§„ë‹¤.
    
- `attention **=** self**.**v(energy)**.**squeeze(2)`
  
    ![Untitled](assets/Untitled%2010.png)
    
    - ìœ„ ìˆ˜ì‹ì— ëŒ€ì‘ë˜ëŠ” ë¶€ë¶„ì´ë‹¤.
    - *`energy = [batch size, src len, dec hid dim]`*
    - ì˜€ë˜ ì°¨ì›ì€ ìœ„ ê³„ì‚°ì„ í†µí•´ì„œ
    - *`attention= [batch size, src len]`*
    - ì°¨ì›ìœ¼ë¡œ ë³€í™”í•˜ê²Œ ëœë‹¤.

- **`return** F**.**softmax(attention, dim**=**1)`
  
    ![Untitled](assets/Untitled%2011.png)
    
    - ìœ„ ìˆ˜ì‹ì— ëŒ€ì‘ë˜ëŠ” ë¶€ë¶„ì´ë‹¤.
    - ìµœì¢…ì ìœ¼ë¡œ src len ê¸¸ì´ ë§Œí¼ì˜, ê°ê°ì˜ src tokenì— ì–¼ë§ˆë§Œí¼ attention í•´ì•¼í•˜ëŠ”ì§€ ê°€ì¤‘ì¹˜ê°€ ë‹´ê¸´ attention vectorê°€ ì‚°ì¶œëœë‹¤.
    

---

### Decoder

### `Weighted source vector`

- ìˆ˜ì‹
  
    ![Untitled](assets/Untitled%2012.png)
    
- encoder hidden states H ì˜ ê°€ì¤‘í•©
- ê°€ì¤‘ì¹˜ëŠ” ğ‘ğ‘¡
  
    

### `decoder hidden state`

- ìˆ˜ì‹
  
    ![Untitled](assets/Untitled%2013.png)
    
- input
    - embedded input word ğ‘‘(ğ‘¦ğ‘¡)
    - weighted source vector ğ‘¤ğ‘¡
    - previous decoder hidden state ğ‘ ğ‘¡âˆ’1
    - ì´ ë•Œ, embedded input wordì™€ weighted source vectorëŠ” concatë˜ì–´ì„œ ë“¤ì–´ê°
- GRU layerë¥¼ ê±°ì¹˜ë©´ì„œ decoder hidden stateë¥¼ ìƒì„±í•¨

### `prediction of the next word`

- ìˆ˜ì‹
  
    ![Untitled](assets/Untitled%2014.png)
    
- input
    - embedded input word ğ‘‘(ğ‘¦ğ‘¡)
    - weighted source vector ğ‘¤ğ‘¡
    - decoder hidden state ğ‘ ğ‘¡
    - 3ê°€ì§€ inputì´ ëª¨ë‘ concat ë˜ì–´ ë“¤ì–´ê°
- linear layer ğ‘“ ë¥¼ ê±°ì³ì„œ ê°€ì¥ ì í•©í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ë‹¨ì–´ë¥¼ ì¶œë ¥í•¨

### `code ì„¤ëª…`

```
#input = [batch size]
input= input.unsqueeze(0)
#input = [1, batch size]

embedded= self.dropout(self.embedding(input))
#embedded = [1, batch size, emb dim]
```

- í•´ë‹¹ time-step inputì˜ embedding ğ‘‘(ğ‘¦ğ‘¡)ì„ ì‚°ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤.

```
a= self.attention(hidden, encoder_outputs)
#a = [batch size, src len]

a= a.unsqueeze(1)
#a = [batch size, 1, src len]
```

- attention layerë¥¼ í†µí•´ attention vectorë¥¼ ì‚°ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤.
- ì´ì „ ì‹œì ì˜ decoder state vectorì™€ encoder outputsê°€ inputìœ¼ë¡œ ë“¤ì–´ê°€ì„œ attention vector ğ‘ğ‘¡ë¥¼ ì‚°ì¶œí•œë‹¤.

```
encoder_outputs= encoder_outputs.permute(1, 0, 2)
#encoder_outputs = [batch size, src len, enc hid dim * 2]

weighted= torch.bmm(a, encoder_outputs)
#weighted = [batch size, 1, enc hid dim * 2]
```

- encoder hidden stateë¥¼ ê°€ì¤‘í•©í•˜ì—¬ weighted vectorë¥¼ ì‚°ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤.
  
    ![Untitled](assets/Untitled%2015.png)
    
- torch.bmm ì—°ì‚°ì„ í•˜ê¸° ìœ„í•´ì„œ encoder outputì„ permuteí•œë‹¤.
- **[batch size, 1, src len]** (a) ê³¼ **[batch size, src len, enc hid dim * 2]** (encoder_outputs) ì‚¬ì´ matrix multiplicationì„ ì§„í–‰í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ weighted **[batch size, 1, enc hid dim * 2]** ë¥¼ ì‚°ì¶œí•œë‹¤.

```python
rnn_input= torch.cat((embedded, weighted), dim= 2)
#rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]

#hidden = [batch size, dec hid dim] (t-1 ì‹œì ì˜ decoder hidden state)
output, hidden= self.rnn(rnn_input, hidden.unsqueeze(0))

#output = [seq len, batch size, dec hid dim * n directions]
#hidden = [n layers * n directions, batch size, dec hid dim]

#seq len, n layers and n directions will always be 1 in this decoder, therefore:
#output = [1, batch size, dec hid dim]
#hidden = [1, batch size, dec hid dim]
#this also means that output == hidden
assert (output == hidden).all()
```

- RNNì„ í†µí•˜ì—¬ í˜„ì¬ tme-step decoder hidden state ğ‘ ğ‘¡ë¥¼ ì‚°ì¶œí•˜ëŠ” ê³¼ì •ì´ë‹¤.
  
    ![Untitled](assets/Untitled%2016.png)
    
- torch.nn.RNNì˜ inputì€ ë‹¤ìŒê³¼ ê°™ì´ ì´ë£¨ì–´ì§„ë‹¤.
  
    ![Untitled](assets/Untitled%2017.png)
    
- ë”°ë¼ì„œ 3ê°€ì§€ input ì¤‘ í˜„ì¬ ì‹œì ì˜ ë‹¨ì–´ì˜ embeddedì™€ weighted vectorëŠ” concatí•˜ì—¬ rnn inputì˜ ì²« ë²ˆì§¸ ì¸ìë¡œ ë“¤ì–´ê°€ê³ , hiddenì€ h_0ìœ¼ë¡œì„œ 2ë²ˆì§¸ ì¸ìë¡œ ë“¤ì–´ê°„ë‹¤.

```python
#embedded = [1, batch size, emb dim]
#output = [1, batch size, dec hid dim]
#weighted = [1, batch size, enc hid dim * 2]

embedded= embedded.squeeze(0)
output= output.squeeze(0)
weighted= weighted.squeeze(0)

prediction= self.fc_out(torch.cat((output, weighted, embedded), dim= 1))
#prediction = [batch size, output dim]
```

- ë‹¤ìŒ ì‹œì ì˜ ë‹¨ì–´ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” ë‹¨ê³„ì´ë‹¤.
  
    ![Untitled](assets/Untitled%2018.png)
    
- output dimì˜ í¬ê¸°ë¡œ predictionì´ ì‚°ì¶œë˜ê³ , ì´ëŠ” ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì— í™œìš©ëœë‹¤.
- output dimì€ dictionaryì˜ numberë¼ê³  í•  ìˆ˜ ìˆê³ , ê°ê°ì˜ vocabì˜ ìœ„ì¹˜ë³„ë¡œ ì–¼ë§ˆë§Œí¼ì˜ í™•ë¥ ì´ ì˜¬ì§€ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•œë‹¤.

---

### seq2seq

### `code ì„¤ëª…`

```
#first input to the decoder is the <sos> tokens

input = trg[0,:]
```

- decoder loopì„ ì‹œì‘í•˜ê¸° ì „ ì²« ë²ˆì§¸ inputìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë‹¨ì–´ëŠ” <sos> í† í°ì´ë¯€ë¡œ, trgì˜ batch sizeë§Œí¼ì˜ sos token id ê°€ inputìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ëœë‹¤.

```
for tin range(1, trg_len):

#insert input token embedding, previous hidden state and all encoder hidden states
#receive output tensor (predictions) and new hidden state

output, hidden= self.decoder(input, hidden, encoder_outputs)
```

- decoderê°€ ë„˜ê²¨ì£¼ëŠ” íŒŒë¼ë¯¸í„°ë¡œëŠ”
    - t ì‹œì ì˜ input
    - t-1 ì‹œì ì˜ hidden state
    - encoderì˜ outputs
    - ìœ„ì˜ 3ê°€ì§€ê°€ ë“¤ì–´ê°€ê²Œ ëœë‹¤.
- decoderê°€ ë°˜í™˜í•´ì£¼ëŠ” ê°’ì€
    - outputì€ decoder codeì—ì„œì˜ predictionìœ¼ë¡œ, target sentenceì˜ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì„ ìœ„í•œ ê°’ì„ ë‚˜íƒ€ë‚¸ë‹¤.
    - hiddenì˜ ê²½ìš° decoderì˜ RNNì„ ì§€ë‚˜ê³  ë‚œ ë’¤ ë‚˜ì˜¤ê²Œ ë˜ëŠ” t ì‹œì ì˜ hidden stateë¥¼ ì˜ë¯¸í•œë‹¤.

```
#get the highest predicted token from our predictions
top1= output.argmax(1)
```

- decoderì˜ output_dimì€ trg_vocab_sizeì™€ ë™ì¼í•œ í¬ê¸°ì´ë‹¤.
- batch ì† í•˜ë‚˜ì˜ exampleì— ëŒ€í•œ output ë²¡í„°ì˜ ê° ì¸ë±ìŠ¤ëŠ”, vocab token idì˜ ì¸ë±ìŠ¤ì™€ ëŒ€ì‘ëœë‹¤.
    - vocab í¬ê¸°ê°€ 4ì¼ ë•Œ, output ë²¡í„°ê°€ ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•˜ì
    
    ```python
    output= [[1.6, 7.8, -4.7, 9.8]] 
    # batchê°€ 1ì´ë¼ê³  ê°€ì •
    ```
    
    - ì´ëŠ” output[0][3]ëŠ” trg_vocab token id 3ë²ˆì— í•´ë‹¹í•˜ëŠ” ê²ƒìœ¼ë¡œ, 4ê°€ì§€ í† í° ì¤‘ 3ë²ˆ í† í°ì´ ë‚˜ì˜¬ í™•ë¥ ì´ ê°€ì¥ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
- ë”°ë¼ì„œ `output.argmax(1)` ì„ í•  ê²½ìš° ê° ë°°ì¹˜ ë³„ë¡œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í† í°ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ê²Œ ë˜ê³ , ì´ëŠ” ì¦‰ trg_vocabì—ì„œì˜ token idë¥¼ ë°˜í™˜í•˜ê²Œ ë˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.

---

### Training the Seq2Seq Model

### `ë³€ìˆ˜ ì„¤ì •`

```
INPUT_DIM= len(SRC.vocab)
OUTPUT_DIM= len(TRG.vocab)
ENC_EMB_DIM= 256
DEC_EMB_DIM= 256
ENC_HID_DIM= 512
DEC_HID_DIM= 512
ENC_DROPOUT= 0.5
DEC_DROPOUT= 0.5
```

- torch.nn.Embedding layerì˜ íŒŒë¼ë¯¸í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.
  
    ![Untitled](assets/Untitled%2019.png)
    
- ê·¸ ì¤‘ input_dim, output_dimdms num_embeddingsì— / enc_emb_dim, dec_emb_dim ì€ embedding dimì— ëŒ€ì‘ëœë‹¤.
- INPUT_DIM ì€ src.vocabì˜ ê¸¸ì´ì™€ ê°™ê³ , encoderì˜ embedding layerì˜ embeddingì˜ dictionary sizeê°€ ëœë‹¤.
- OUTPUT_DIMì€ trag.vocabì˜ ê¸¸ì´ì™€ ê°™ê³ , decoderì˜ embedding layerì˜ embeddingì˜ dictionary sizeê°€ ëœë‹¤.
- ENC_EMB_DIMì€ encoderì˜ embedding layerì˜ embedding dimì´ ëœë‹¤.
- DEC_EMB_DIMì€ decoderì˜ embedding layerì˜ embedding dimì´ ëœë‹¤.

### `train`

- trainì€ batch ë‹¨ìœ„ë¡œ srcì™€ trgì´ ë“¤ì–´ê°€ë©´ì„œ ì´ë£¨ì–´ì§„ë‹¤.

```
for i, batch in enumerate(iterator):

	src= batch.src
	trg= batch.trg
```

- ì²« ë²ˆì§¸ batchì—ì„œì˜ srcì˜ ê°’ê³¼ trgì˜ ê°’ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
    - src  *`[src len, batch size]`*
    
    ```python
    tensor([[  2,   2,   2,  ...,   2,   2,   2],
            [ 18,   8,  17,  ...,   8,  18,  18],
            [103,  16, 523,  ...,  36, 103, 168],
            ...,
            [  1,   1,   1,  ...,   1,   1,   1],
            [  1,   1,   1,  ...,   1,   1,   1],
            [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')
    ```
    
    - trg  *`[trg len, batch size]`*
    
    ```python
    tensor([[ 2,  2,  2,  ...,  2,  2,  2],
            [ 7,  4,  4,  ...,  4,  4, 19],
            [14,  9, 38,  ..., 64, 38, 41],
            ...,
            [ 1,  1,  1,  ...,  1,  1,  1],
            [ 1,  1,  1,  ...,  1,  1,  1],
            [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')
    ```
    
- ì´ë¥¼ í†µí•´ì„œ <sos> í† í°ì˜ ê²½ìš° vocabì—ì„œì˜ token idxëŠ” 2, <pad> í† í°ì˜ ê²½ìš° vocabì—ì„œì˜ token idxëŠ” 1ì´ë¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

- outputì˜ ê²°ê³¼

```python
output = model(src, trg)
        
#output = [trg len, batch size, output dim]
```

- outputì€ ê° trg lenì˜ time-stepë³„ë¡œ í•´ë‹¹ time-stepì—ì„œ ë‚˜ì˜¬ ë‹¨ì–´ ì¤‘ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê²¨ìˆë‹¤.
    - ì´ ì •ë³´ëŠ” 3ë²ˆì§¸ ì°¨ì›ì¸ output_dimì—ì„œ í™•ì¸í•  ìˆ˜ ìˆê³ , ì´ë¥¼ ì´ìš©í•˜ì—¬ lossë¥¼ ê³„ì‚°í•˜ì—¬ í•™ìŠµì´ ì´ë£¨ì–´ì§„ë‹¤.

- loss ê³„ì‚°ì˜ ê³¼ì •

```
output= output[1:].view(-1, output_dim)
trg= trg[1:].view(-1)

#output = [(trg len - 1) * batch size, output dim]
#trg = [(trg len - 1) * batch size]
```

- outputê³¼ trgëª¨ë‘ ì²« ë²ˆì§¸ ì°¨ì›ì—ì„œ 0ë²ˆ ì¸ë±ìŠ¤ì˜ ê°’ì„ ë°°ê³  [1:]ë¡œ ì§„í–‰í•˜ëŠ” ì´ìœ ëŠ”, ì²«ë²ˆì§¸ í† í°ì˜ ê°’ì€ <sos> ë¡œì¨ ì œì™¸í•˜ê³  ì§„í–‰í•˜ê¸° ìœ„í•¨ì´ë‹¤.
- outputì€ 2ì°¨ì›ìœ¼ë¡œ, trgì€ 1ì°¨ì›ìœ¼ë¡œ ì°¨ì›ì„ ë³€ê²½ì‹œí‚¨ë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´ì„œ batch size=1, trg len=4, output_dim=5ë¼ê³  í–ˆì„ ë•Œ
    - output ì€ ê° ì‹œì ê³¼ batch ë³„ vocabì— ìˆëŠ” ë‹¨ì–´ ì¤‘ ë‹¤ìŒ í† í°ì´ ë  ë‹¨ì–´ë“¤ì˜ í™•ë¥ ì„ ë‚˜íƒ€ë‚¸ë‹¤.
    
    ```python
    [[0.9, 9.8, -3.0, 2.0, 4.6], # ì‹œì  0, batch 1ì—ì„œì˜ ë‹¨ì–´ë“¤ì˜ í™•ë¥ ê°’ ì¡°í•©
     [0.9, 0.8, -5.0, -7.0, 4.8], # ì‹œì  1, batch 1ì—ì„œì˜ ë‹¨ì–´ë“¤ì˜ í™•ë¥ ê°’ ì¡°í•©
     [1.4, 5.8, 8.0, 4.0, 4.6], # ì‹œì  2, batch 1ì—ì„œì˜ ë‹¨ì–´ë“¤ì˜ í™•ë¥ ê°’ ì¡°í•©
     [-2.9, -5.8, -1.1, 2.0, 9.6]] # ì‹œì  3, batch 1ì—ì„œì˜ ë‹¨ì–´ë“¤ì˜ í™•ë¥ ê°’ ì¡°í•©
    ```
    
    - trg ì€ ê° ì‹œì ê³¼ batchë³„ vocabì— ìˆëŠ” ì •ë‹µ toekn idë¥¼ ê°€ì§„ë‹¤.
    
    ```python
    [[2], # ì‹œì  0, batch 1ì—ì„œì˜ ì •ë‹µ token id
     [1], # ì‹œì  1, batch 1ì—ì„œì˜ ì •ë‹µ token id
     [4], # ì‹œì  2, batch 1ì—ì„œì˜ ì •ë‹µ token id
     [3]] # ì‹œì  3, batch 1ì—ì„œì˜ ì •ë‹µ token id
    ```
    

```
loss= criterion(output, trg)

loss.backward()
```

- ì—¬ê¸°ì„œ lossëŠ” cross entropy lossë¥¼ ì‚¬ìš©í•œë‹¤.
- `criterion **=** nn**.**CrossEntropyLoss(ignore_index **=** TRG_PAD_IDX)`
- ì½”ë“œì—ëŠ” ìœ„ì™€ ê°™ì´ ì •ì˜ë˜ì–´ ìˆê³ , pad indexì— ëŒ€í•´ì„œëŠ” loss ê³„ì‚°ì„ í•˜ì§€ ì•Šë„ë¡ ì„¤ì •ë˜ì–´ ìˆë‹¤.
- cross entropy êµ¬í•˜ê¸°
    - cross entropy ì˜ inputìœ¼ë¡œëŠ” ë‹¤ìŒì˜ 2ê°€ì§€ê°€ ë“¤ì–´ê°„ë‹¤.
        - `score` Â = [Batch size x the number of Class]
            - ê° class ë³„ë¡œ í™•ë¥ ì„ operationí•œ ê²°ê³¼ (ì´ ì½”ë“œì—ì„œëŠ” output)
        - `target` Â = [Batch size]
            - ì •ë‹µ classë¥¼ ê°€ë¦¬í‚¤ëŠ” target ê°’ (ì´ ì½”ë“œì—ì„œëŠ” trg)
        - inputì—ì„œ ì£¼ì˜í•´ì•¼í•  ì ì€ crossentropylossì—ëŠ” ì´ë¯¸ logsoftmaxê°€ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— inputì„ ë„£ì„ ë•ŒëŠ” log ê°’ì´ ì”Œì›Œì§„ outputê°’ì´ ì•„ë‹Œ ìƒ outputê°’ì„ ì¤˜ì•¼í•œë‹¤.
    
    - cross entropy ìˆ˜ì‹ ê³„ì‚° ê³¼ì •
        - outputìœ¼ë¡œ ë‚˜ì˜¨ scoreì— `torch.exp` ë¥¼ ì”Œìš´ë‹¤.
        - `torch.sum()` ìœ¼ë¡œ ëª¨ë‘ ë”í•´ì¤€ë‹¤.
        - `torch.log` ë¥¼ ì”Œì›Œì¤€ë‹¤.
        - targetì´ ì •ë‹µ class indexë¼ê³ í•  ë•Œ, output[target]ì˜ ê°’ì„ ì „ì²´ ê°’ì—ì„œ ë¹¼ì¤˜ì„œ ìµœì¢… lossë¥¼ êµ¬í•œë‹¤.
        
        â†’ ì´ë ‡ê²Œ í•˜ê²Œ ë˜ë©´, outputì—ì„œ targetì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ì˜ ìš”ì†Œê°€ ë†’ì€ ê°’ì„ ê°€ì§ˆ ìˆ˜ë¡ lossê°€ ë‚®ê²Œ ë§Œë“¤ì–´ì§€ê²Œ ë˜ë¯€ë¡œ, í•´ë‹¹ targetì— í•´ë‹¹í•˜ëŠ” ê°’ì´ í™•ë¥ ê°’ì´ í¬ê²Œ ê°–ê²Œ ë˜ë„ë¡ í•™ìŠµëœë‹¤. 
        
    
- optimizerì„ í†µí•´ backpropagationì´ ì¼ì–´ë‚˜ê³  ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì˜ ì—…ë°ì´íŠ¸ë˜ë©° í•™ìŠµì´ ì§„í–‰ëœë‹¤.

### `evaluate`

- loss ê³„ì‚°
  
    ```python
    output = output[1:].view(-1, output_dim)
    trg = trg[1:].view(-1)
    
    #trg = [(trg len - 1) * batch size]
    #output = [(trg len - 1) * batch size, output dim]
    
    loss = criterion(output, trg)
    ```
    
    - trainì—ì„œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ lossê°€ ê³„ì‚°ëœë‹¤.
    - `model.eval()` ë¡œ ì„¤ì •í•˜ì˜€ìœ¼ë¯€ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ì™€ backpropagationì€ ì¼ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤.